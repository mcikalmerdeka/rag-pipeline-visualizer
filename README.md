# ğŸ” RAG Pipeline Visualizer

An interactive tool to visualize the complete **naive RAG process** from start to finish. This project breaks down the entire RAG (Retrieval-Augmented Generation) pipeline into three transparent sections: **Indexing & Retrieval â†’ Augmentation â†’ Generation**. Built with Streamlit, ChromaDB, Sentence Transformers, and OpenAI.

ğŸš€ **Try it live here: [Streamlit Cloud](https://rag-pipeline-visualizer-3qng3jzjaatt7fyccnshzy.streamlit.app/)**

<div align="center">
  <img src="https://raw.githubusercontent.com/mcikalmerdeka/rag-pipeline-visualizer/main/assets/Clearest%20RAG%20Diagram.jpg" alt="RAG Pipeline Diagram" width="500"/>
</div>

## ğŸŒŸ Features

### ğŸ” Section 1: Indexing & Retrieval

- **Text Processing**: Upload files or paste content directly
- **Smart Chunking**: Configurable chunk size and overlap
- **Embedding Models**: Choose **all-MiniLM-L6-v2** (fast, local) or **OpenAI text-embedding-3-small** (cloud)
- **ChromaDB Integration**: Real vector database storage
- **Enhanced Visualizations**: ğŸŒŸ **NEW!** Three visualization modes:
  - **3D Scatter Plot**: Interactive 3D embedding space
  - **2D Network Graph**: Semantic relationship networks
  - **2D Scatter with Connections**: Combined spatial and relational view
- **Semantic Search**: Query and see similar chunks highlighted
- **Relationship Discovery**: Find and visualize semantic neighbors

### ğŸ”§ Section 2: Augmentation

- **System Prompt Management**: View and customize prompts
- **Context Display**: See retrieved chunks formatted for LLM
- **Prompt Preview**: View complete augmented message
- **Token Estimation**: Calculate costs before generation
- **LangSmith-style UI**: Professional observability interface

### âœ¨ Section 3: Generation

- **OpenAI Integration**: GPT-4o-mini response generation
- **Token Usage**: Detailed breakdown of prompt/completion tokens
- **Cost Tracking**: Real-time cost estimation
- **API Inspection**: Full request/response visibility
- **Regenerate**: Easy response regeneration

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/mcikalmerdeka/rag-pipeline-visualizer.git
cd rag-pipeline-visualizer
```

### 2. Install Dependencies

**Option A â€“ pip**

```bash
pip install -r requirements.txt
```

**Option B â€“ uv**

```bash
uv sync
```

Or install from `requirements.txt` explicitly:

```bash
uv add -r requirements.txt
```

### 3. Configure OpenAI API Key

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your_openai_api_key_here
```

Get your API key from [OpenAI Platform](https://platform.openai.com/api-keys).

### 4. Run the App

```bash
streamlit run app.py
```

The app opens at `http://localhost:8501`

> **Note**: First run may download the embedding model (~80MB for all-MiniLM-L6-v2). Using OpenAI embeddings skips local download but requires an API key.

### 5. Try It Out

1. In **Indexing & Retrieval**: Click "Load Sample" in sidebar â†’ Choose "AI & Machine Learning"
2. Click "Generate Embeddings" (wait ~10 seconds for local model, or use OpenAI for cloud embeddings)
3. **Explore Visualizations**: Try different visualization modes to see semantic relationships
4. Enter query: "What is deep learning?"
5. Click "Search Similar Chunks"
6. **See Retrieved Chunks**: Notice how they're highlighted in the visualization
7. Scroll to **Augmentation** section â†’ Review prompt
8. Click "Proceed to Generation"
9. Scroll to **Generation** section â†’ Click "Generate Response"

## ğŸ“– Complete RAG Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. INDEXING & RETRIEVAL â”‚
â”‚  â€¢ Chunk text           â”‚
â”‚  â€¢ Generate embeddings  â”‚
â”‚  â€¢ Store in ChromaDB    â”‚
â”‚  â€¢ Query â†’ embed â†’      â”‚
â”‚    similarity search    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. AUGMENTATION â”‚
â”‚  â€¢ System       â”‚
â”‚    prompt       â”‚
â”‚  â€¢ Retrieved    â”‚
â”‚    context      â”‚
â”‚  â€¢ User query   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. GENERATION   â”‚
â”‚  â€¢ Call OpenAI  â”‚
â”‚  â€¢ Get response â”‚
â”‚  â€¢ Track tokens â”‚
â”‚  â€¢ View cost    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Use Cases

- **Learning RAG**: Understand the complete pipeline visually
- **Prompt Engineering**: See exact prompts sent to LLM
- **Cost Analysis**: Track token usage and costs
- **Model Comparison**: Compare embedding models
- **Document Analysis**: Explore semantic relationships
- **Education**: Teach vector databases and RAG systems
- **Debugging**: Inspect full API calls and responses

## ğŸ› ï¸ Technical Stack

- **Streamlit**: Web interface and interactivity
- **Sentence Transformers**: State-of-the-art embeddings
- **ChromaDB**: Vector database for semantic search
- **OpenAI**: GPT-4o-mini for generation
- **Plotly**: Interactive 3D visualizations
- **NetworkX**: Graph-based semantic network visualization
- **scikit-learn & UMAP**: Dimensionality reduction

## ğŸ§ª Supported Models

### Embedding Models

| Model                         | Type  | Speed  | Best For                 |
| ----------------------------- | ----- | ------ | ------------------------ |
| all-MiniLM-L6-v2 (Fast)       | Local | âš¡âš¡âš¡ | General use, no API key  |
| OpenAI text-embedding-3-small | Cloud | âš¡âš¡   | Higher quality, uses API |

Default and other options can be changed in `src/config/settings.py`.

### LLM Model

- **GPT-4.1-mini** (default): Fast, affordable, high-quality responses. Default model, temperature, and system prompt are configurable in `src/config/settings.py`.
- **Pricing**: ~$0.0001-0.0015 per query (very affordable!)

## ğŸ“Š Observability & Educational Features

Similar to LangSmith, with enhanced educational visualizations:

**RAG Pipeline Transparency:**

- âœ… **Prompt Construction**: Exact system prompt and user message
- âœ… **Context Injection**: How retrieved chunks are formatted
- âœ… **Token Usage**: Detailed breakdown of input/output tokens
- âœ… **Cost Tracking**: Estimated costs per generation
- âœ… **Full Conversation**: Complete API request/response
- âœ… **Similarity Scores**: Which chunks were most relevant

**Enhanced Visualizations:**

- âœ… **3D Scatter Plot**: Spatial distribution of embeddings
- âœ… **2D Network Graph**: Semantic relationship networks with clustering
- âœ… **2D Scatter with Connections**: Combined spatial and relational view
- âœ… **Interactive Controls**: Adjust neighbors, similarity threshold, layouts
- âœ… **Educational Tooltips**: Learn what each parameter does
- âœ… **Hover Information**: See chunk content and similar neighbors

## ğŸ“ Project Structure

```
RAG Visualizer/
â”œâ”€â”€ app.py                              # Main application
â”œâ”€â”€ requirements.txt                    # Dependencies
â”œâ”€â”€ .env                               # API keys (create this)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ settings.py               # Model options, samples
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ models.py                 # Embedding models
â”‚   â”‚   â”œâ”€â”€ text_processing.py       # Text chunking
â”‚   â”‚   â”œâ”€â”€ vector_store.py           # ChromaDB operations
â”‚   â”‚   â”œâ”€â”€ visualization.py          # 3D plotting
â”‚   â”‚   â”œâ”€â”€ network_visualization.py  # Network graphs (NEW!)
â”‚   â”‚   â”œâ”€â”€ llm.py                    # OpenAI integration
â”‚   â”‚   â””â”€â”€ session_state.py          # State management
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ styles.py                 # CSS styling
â”‚       â””â”€â”€ components/               # UI components
â”‚           â”œâ”€â”€ input_section.py
â”‚           â”œâ”€â”€ query_section.py
â”‚           â”œâ”€â”€ visualization_section.py
â”‚           â”œâ”€â”€ augmentation_section.py
â”‚           â””â”€â”€ generation_section.py
â”œâ”€â”€ README.md                          # This file
â””â”€â”€ DEPLOYMENT_GUIDE.md               # Cloud deployment
```

## ğŸ’° Cost Considerations

**GPT-4o-mini Pricing:**

- Input: $0.150 per 1M tokens
- Output: $0.600 per 1M tokens

**Typical Query Cost:**

- Small (3 contexts, 500 tokens): ~$0.0001-0.0003
- Medium (5 contexts, 1500 tokens): ~$0.0003-0.0008
- Large (10 contexts, 3000 tokens): ~$0.0006-0.0015

**Local Operations (Free):**

- Retrieval: Local embeddings (sentence-transformers)
- Augmentation: Client-side prompt construction

## ğŸ³ Docker Deployment

Quick start with Docker Compose:

```bash
# Build and run
docker-compose up -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

Or build manually:

```bash
docker build -t rag-visualizer .
docker run -p 8501:8501 --env-file .env rag-visualizer
```

See [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) for cloud deployment options (Google Cloud Run, AWS, Azure).

## ğŸ’¡ Tips for Best Results

**Chunk Size:**

- Smaller (50-100) = more granular, specific queries
- Larger (200-500) = more context, conceptual queries

**Visualization Mode:**

- Start with **3D Scatter** for overall understanding
- Use **Network Graph** to discover semantic clusters
- Try **2D Scatter with Connections** for combined insights
- Adjust **Semantic Neighbors** (5 is recommended for balanced view)
- Lower **Similarity Threshold** (0.3-0.4) to see more connections

**System Prompt:**

- Customize for your use case (technical docs, customer support, research)
- Include instructions for citation and fallback behavior

**Token Management:**

- Reduce retrieved chunks (n_results) to lower costs
- Use smaller chunk sizes for efficiency
- Monitor token usage in the Generation section

**Model Selection:**

- **all-MiniLM-L6-v2**: Local, fast, no API key; good for learning and offline use
- **OpenAI text-embedding-3-small**: Cloud; use when you want higher-quality embeddings and have an API key

## ğŸ”§ Troubleshooting

**"OPENAI_API_KEY not found"**

- Ensure `.env` file exists in project root
- Verify format: `OPENAI_API_KEY=sk-...`
- Restart Streamlit after creating `.env`

**High token usage**

- Reduce number of retrieved chunks (n_results slider)
- Use smaller chunk sizes
- Shorten the system prompt

**Model download fails**

```bash
export TRANSFORMERS_CACHE="./models"
streamlit run app.py
```

**Port already in use**

```bash
streamlit run app.py --server.port 8502
```

## ğŸ¨ Enhanced Visualizations

The application includes three powerful visualization modes inspired by advanced embedding analysis techniques, designed to help users understand semantic relationships in their data:

### Visualization Modes

**1. 3D Scatter Plot**

- Best for: Overall spatial understanding
- Shows: Chunks as points in 3D space after dimensionality reduction
- Use when: You want to see the big picture of how content is distributed

**2. 2D Network Graph** ğŸŒŸ

- Best for: Discovering semantic clusters and relationships
- Shows: Chunks as connected nodes with similarity-based edges
- Use when: You want to find hidden relationships and content groupings
- Features: Multiple layout algorithms (spring, circular, kamada-kawai)

**3. 2D Scatter with Connections** ğŸŒŸ

- Best for: Understanding both position and relationships
- Shows: 2D embedding space with similarity connections
- Use when: You want to combine spatial distribution with semantic links

### Interactive Controls

All visualizations include educational controls:

- **Semantic Neighbors** (2-10): How many similar chunks to connect
- **Similarity Threshold** (0.0-1.0): Minimum similarity to show connections
- **Graph Layout**: Different algorithms reveal different patterns
- **Hover Information**: See chunk content and similar neighbors
- **Color Coding**: ğŸŸ£ Regular | ğŸ”´ Retrieved | ğŸŸ¡ Query

### Why These Visualizations?

These features were inspired by advanced embedding analysis research but implemented with lightweight, production-ready models (sentence-transformers) to ensure:

- âš¡ Fast performance (~50ms per query)
- ğŸ’¾ Low memory usage (~100MB)
- ğŸ¯ Optimized for educational purposes
- ğŸ“š Clear, interpretable results

## ğŸ”® Future Enhancements

- [ ] Support for other LLM providers (Anthropic, local models)
- [ ] Conversation history
- [ ] RAG evaluation metrics (faithfulness, relevance)
- [ ] PDF and DOCX support
- [ ] Streaming responses
- [ ] Prompt template library
- [ ] Advanced RAG techniques (HyDE, multi-query)
- [ ] Export/import functionality

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

## ğŸ“ License

MIT License - see [LICENCE](LICENCE) file for details.

## ğŸ™ Acknowledgments

- [Sentence Transformers](https://www.sbert.net/) - Embedding models
- [ChromaDB](https://www.trychroma.com/) - Vector database
- [OpenAI](https://openai.com/) - LLM API
- [Streamlit](https://streamlit.io/) - Web framework
- [Plotly](https://plotly.com/) - Interactive visualizations
- [NetworkX](https://networkx.org/) - Graph analysis and visualization
- [scikit-learn](https://scikit-learn.org/) & [UMAP](https://umap-learn.readthedocs.io/) - Dimensionality reduction

---

â­ If you find this project helpful, please give it a star!
